import json
import numpy as np
from typing import List, Dict, Any

class SimpleRAGSystem:
    def __init__(self, vectors_file='tz_vectors.json'):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ—Å—Ç–æ–π RAG —Å–∏—Å—Ç–µ–º—ã"""
        with open(vectors_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
            self.vectors = data['vectors']
            
        self.embeddings_matrix = np.array([vec['embedding'] for vec in self.vectors])
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.vectors)} –±–ª–æ–∫–æ–≤ –∏–∑ –¢–ó")
    
    def vectorize_query(self, query: str) -> np.ndarray:
        """–ü—Ä–æ—Å—Ç–∞—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ —á–µ—Ä–µ–∑ TF-IDF like –ø–æ–¥—Ö–æ–¥"""

        all_texts = [vec['text'] for vec in self.vectors]
        all_words = set()
        for text in all_texts:
            words = text.lower().split()
            all_words.update(words)
        
        query_words = query.lower().split()
        query_vector = np.zeros(len(self.vectors[0]['embedding']))
        
        for i, word in enumerate(query_words):
            if i < len(query_vector):
                query_vector[i] = 1.0 / (i + 1)  # –£–º–µ–Ω—å—à–∞–µ–º –≤–µ—Å –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–∏—Ö —Å–ª–æ–≤
      
        norm = np.linalg.norm(query_vector)
        if norm > 0:
            query_vector = query_vector / norm
            
        return query_vector
    
    def find_similar_vectors(self, query: str, top_k: int = 3) -> List[Dict]:
        """–ù–∞—Ö–æ–¥–∏—Ç –Ω–∞–∏–±–æ–ª–µ–µ –ø–æ—Ö–æ–∂–∏–µ –≤–µ–∫—Ç–æ—Ä—ã –Ω–∞ –∑–∞–ø—Ä–æ—Å"""

        query_vector = self.vectorize_query(query)
        
        if query_vector is None:
            return []
        
        similarities = np.dot(self.embeddings_matrix, query_vector)
        
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        
        results = []
        for idx in top_indices:
            vec = self.vectors[idx]
            similarity = float(similarities[idx])
            
            results.append({
                'id': vec['id'],
                'section': vec['section'],
                'text': vec['text'],
                'hash': vec['hash'],
                'similarity': similarity,
                'relevance_percentage': min(100, max(0, (similarity + 1) * 50))
            })
        
        results.sort(key=lambda x: x['relevance_percentage'], reverse=True)
        return results
    
    def generate_response(self, query: str, context_blocks: List[Dict]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤"""
        if not context_blocks:
            return {
                'query': query,
                'response': "–ü–æ –≤–∞—à–µ–º—É –∑–∞–ø—Ä–æ—Å—É –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –¢–ó.",
                'suggestion': "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∏–∑ –¢–ó: –ø—Ä–æ—Ü–µ–¥—É—Ä–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è, –∫–æ–¥–µ–∫—Å, RPG, –ø–ª–∞–Ω–µ—Ç—ã, MVP –∏ —Ç.–¥."
            }
        
        response_parts = []
        response_parts.append(f"üîç **–û—Ç–≤–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å:** '{query}'")
        response_parts.append("")
        response_parts.append("üìã **–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤ –¢–ó:**")
        
        for i, block in enumerate(context_blocks[:3]):
            response_parts.append(f"\n{i+1}. **{block['section']}** (—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {block['relevance_percentage']:.1f}%)")
            
            lines = block['text'].split('\n')
            preview = ' | '.join([line.strip() for line in lines if line.strip()][:2])
            if len(preview) > 150:
                preview = preview[:147] + "..."
            response_parts.append(f"   {preview}")
        
        response_parts.append("\nüìù **–ö–ª—é—á–µ–≤—ã–µ –º–æ–º–µ–Ω—Ç—ã:**")
        
        keywords = set()
        for block in context_blocks[:3]:
          
            lines = block['text'].split('\n')
            for line in lines:
                words = line.split(':')
                if len(words) > 1:
                    keywords.add(words[0].strip())
        
        for keyword in list(keywords)[:5]:
            response_parts.append(f"   ‚Ä¢ {keyword}")
        
        response_parts.append(f"\nüìä **–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:** –ù–∞–π–¥–µ–Ω–æ {len(context_blocks)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –±–ª–æ–∫–æ–≤, —Å—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {np.mean([b['relevance_percentage'] for b in context_blocks]):.1f}%")
        
        response = "\n".join(response_parts)
        
        return {
            'query': query,
            'context_blocks': context_blocks,
            'response': response,
            'total_blocks_found': len(context_blocks),
            'avg_relevance': np.mean([b['relevance_percentage'] for b in context_blocks])
        }
    
    def query(self, question: str, top_k: int = 5) -> Dict[str, Any]:
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞"""
        print(f"\n{'='*60}")
        print(f"üéØ –ó–∞–ø—Ä–æ—Å: {question}")
        print('='*60)
        
        similar_blocks = self.find_similar_vectors(question, top_k)
        
        relevant_blocks = [b for b in similar_blocks if b['relevance_percentage'] > 30]
        
        response = self.generate_response(question, relevant_blocks)
        
        print("\n" + response['response'])
        
        print(f"\n{'='*60}")
        print("üîß –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:")
        print(f"   ‚Ä¢ –ù–∞–π–¥–µ–Ω–æ –±–ª–æ–∫–æ–≤: {response['total_blocks_found']}")
        print(f"   ‚Ä¢ –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å: {response['avg_relevance']:.1f}%")
        
        if response['context_blocks']:
            print(f"\nüìö –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏ –¢–ó:")
            for block in response['context_blocks'][:3]:
                print(f"   [{block['hash']}] {block['section'][:40]}... ({block['relevance_percentage']:.1f}%)")
        
        print('='*60)
        
        return response

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã"""
    
    print("üöÄ –ó–∞–≥—Ä—É–∑–∫–∞ RAG —Å–∏—Å—Ç–µ–º—ã –¥–ª—è –¢–ó '–ó–≤–µ–∑–¥–Ω—ã–π –ö–æ–¥–µ–∫—Å'...")
    rag_system = SimpleRAGSystem('tz_vectors.json')
    
    test_queries = [
        "–ö–∞–∫–∏–µ –æ–±—Ä–∞–∑–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ –¥–∏—Å—Ü–∏–ø–ª–∏–Ω—ã –µ—Å—Ç—å –≤ –∏–≥—Ä–µ?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–æ—Ü–µ–¥—É—Ä–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è?",
        "–ö–∞–∫–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–≥—Ä–∞?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ MVP?",
        "–ö–∞–∫–∏–µ –Ω–∞–≤—ã–∫–∏ —É –ø–µ—Ä—Å–æ–Ω–∞–∂–∞?",
        "–ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å–∏—Å—Ç–µ–º–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è?",
        "–ö–∞–∫–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è?",
        "–ß—Ç–æ —Ç–∞–∫–æ–µ –ö–æ–¥–µ–∫—Å –≤ –∏–≥—Ä–µ?",
        "–ö–∞–∫–∏–µ —É–≥—Ä–æ–∑—ã –µ—Å—Ç—å –≤ –∏–≥—Ä–µ?",
        "–ö–∞–∫–æ–π —Å—Ç–∏–ª—å –≥—Ä–∞—Ñ–∏–∫–∏?"
    ]
    
    print("\nüß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤...")
    
    for i, query in enumerate(test_queries, 1):
        print(f"\n{'#'*60}")
        print(f"–¢–µ—Å—Ç {i}/{len(test_queries)}")
        rag_system.query(query)
        
        if i < len(test_queries):
            input("\n–ù–∞–∂–º–∏—Ç–µ Enter –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞...")
    
    print(f"\n{'='*60}")
    print("üí¨ –ò–ù–¢–ï–†–ê–ö–¢–ò–í–ù–´–ô –†–ï–ñ–ò–ú")
    print("="*60)
    print("–í–≤–æ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å—ã –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.")
    print("–ü—Ä–∏–º–µ—Ä—ã —Ö–æ—Ä–æ—à–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤:")
    print("  - '–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ –∏–≥—Ä–µ'")
    print("  - '–≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–ª–∞–Ω–µ—Ç'")
    print("  - '–∏–≥—Ä–æ–≤–∞—è –º–µ—Ö–∞–Ω–∏–∫–∞'")
    print("  - '–∞—Ä—Ç –∏ –∑–≤—É–∫'")
    print("–í–≤–µ–¥–∏—Ç–µ '–≤—ã—Ö–æ–¥' –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è.\n")
    
    while True:
        user_query = input("üéØ –í–∞—à –∑–∞–ø—Ä–æ—Å: ").strip()
        
        if user_query.lower() in ['–≤—ã—Ö–æ–¥', 'exit', 'quit', 'q']:
            print("–ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã...")
            break
        
        if not user_query:
            continue
        
        try:
            rag_system.query(user_query)
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            print("–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –¥—Ä—É–≥–æ–π –∑–∞–ø—Ä–æ—Å.")

if __name__ == "__main__":
    main()
